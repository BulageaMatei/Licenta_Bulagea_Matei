{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6aab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "(2, 1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Image datasets and image manipulation\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import glob\n",
    "import warnings\n",
    "from imutils import face_utils\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "########\n",
    "#DATASETS\n",
    "#PregÄƒtim dataseturile pentru a le putea utiliza\n",
    "\n",
    "URL1 = \"E:\\\\Profil\\\\Desktop\\\\Licenta\\\\ISIA\\\\LICENTA\\\\poze_eu_masca\"\n",
    "URL2 = \"E:\\\\Profil\\\\Desktop\\\\Licenta\\\\ISIA\\\\LICENTA\\\\poze_eu_fara_masca\"\n",
    "\n",
    "def import_and_do_datasets(URL1, URL2):\n",
    "    transform_test = transforms.Compose(\n",
    "    [transforms.Resize((224,224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "    #Importam dataset pentru demascare faciala, respectiv identificare parte superioara\n",
    "    image_Datasets_WithMask = datasets.ImageFolder(URL1, transform = transform_test)\n",
    "    image_Datasets_WithoutMask =  datasets.ImageFolder(URL2, transform = transform_test)\n",
    "\n",
    "    #Cream data loader pentru datasetul cu demascarea \n",
    "    dataloaders_WithMask = torch.utils.data.DataLoader(image_Datasets_WithMask, batch_size = 1, shuffle = False, num_workers = 4)\n",
    "    dataloaders_WithoutMask = torch.utils.data.DataLoader(image_Datasets_WithoutMask, batch_size = 1, shuffle = False, num_workers = 4)\n",
    "    \n",
    "    return transform_test, image_Datasets_WithMask, image_Datasets_WithoutMask, dataloaders_WithMask, dataloaders_WithoutMask\n",
    "    \n",
    "\n",
    "def model_mask_output(image_path, model_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    #model = models.resnet50(weights=ResNet50_Weights.DEFAULT).to(device) # cele mai actuale weights, dar are probleme \n",
    "    model = models.resnet50(pretrained=True).to(device)   #importam resnet\n",
    "\n",
    "\n",
    "    # freezing pretrained layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True \n",
    "\n",
    "    model.fc = nn.Sequential(\n",
    "            nn.Dropout(p = 0.5, inplace = False),\n",
    "            nn.Linear(in_features = 2048, out_features =128, bias = True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5, inplace = False),\n",
    "            nn.Linear(in_features = 128, out_features = 2, bias = True)).to(device)\n",
    "\n",
    "    \n",
    "    #Load the model\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    validation_image = torch.stack([transform_test(image).to(device)])\n",
    "    \n",
    "    pred_logits_tensor = model(validation_image)\n",
    "    pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\n",
    "    \n",
    "    if pred_probs[0, 0] >= 0.5:\n",
    "        out = 1\n",
    "    else:\n",
    "        out = 0\n",
    "    \n",
    "    return out\n",
    "\n",
    "def model_people(image_path, model_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    #model = models.resnet50(weights=ResNet50_Weights.DEFAULT).to(device) # cele mai actuale weights, dar are probleme \n",
    "    model_people = models.resnet50(pretrained=True).to(device)            #importam resnet\n",
    "\n",
    "\n",
    "    # freezing pretrained layers\n",
    "    for param in model_people.parameters():\n",
    "        param.requires_grad = True \n",
    "\n",
    "    model_people.fc = nn.Sequential(\n",
    "                nn.Dropout(p = 0.5, inplace = False),\n",
    "                nn.Linear(in_features = 2048, out_features =128, bias = True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p = 0.5, inplace = False),\n",
    "                nn.Linear(in_features = 128, out_features = 10, bias = True)).to(device)\n",
    "    \n",
    "    model_people.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_people.eval()\n",
    "    \n",
    "    validation_image = torch.stack([transform_test(image).to(device)])\n",
    "    \n",
    "    pred_logits_tensor = model_people(validation_image)\n",
    "    pred_probs = F.softmax(pred_logits_tensor).cpu().data.numpy()\n",
    "    \n",
    "    return pred_probs\n",
    "\n",
    "def check_person(vector):\n",
    "    \n",
    "    vector = vector.flatten()\n",
    "    max_index = np.argmax(vector)\n",
    "    \n",
    "    return max_index\n",
    "\n",
    "def replace_red_with_color(image):\n",
    "    for y in range(w1):\n",
    "        for x in range(h1):\n",
    "            blue_channel  = image[y,x,0]\n",
    "            green_channel = image[y,x,1]\n",
    "            red_channel   = image[y,x,2]\n",
    "            if red_channel >= 200 and green_channel >= 10 and green_channel <= 50 and blue_channel >= 55 :\n",
    "                image[y,x] = [0,0,0]\n",
    "\n",
    "\n",
    "def replace_cyan_with_color(image):\n",
    "    for y in range(w1):\n",
    "        for x in range(h1):\n",
    "            blue_channel  = image[y,x,0]\n",
    "            green_channel = image[y,x,1]\n",
    "            red_channel   = image[y,x,2]\n",
    "            if red_channel <= 75 and green_channel >= 100 and blue_channel >= 100 :\n",
    "                image[y,x] = [0,0,0]   \n",
    "\n",
    "\n",
    "def replace_green_with_color(image):\n",
    "    for y in range(w1):\n",
    "        for x in range(h1):\n",
    "            blue_channel  = image[y,x,0]\n",
    "            green_channel = image[y,x,1]\n",
    "            red_channel   = image[y,x,2]            \n",
    "            if red_channel <= 50 and green_channel >= 200 and blue_channel <= 50:\n",
    "                image[y,x] = [0,0,0]    \n",
    "\n",
    "\n",
    "def replace_black_with_color(image):          \n",
    "    for y in range(w1):\n",
    "        for x in range(h1):\n",
    "            blue_channel  = image[y,x,0]\n",
    "            green_channel = image[y,x,1]\n",
    "            red_channel   = image[y,x,2]\n",
    "            if np.all(image[y, x] == [0,0,0]):\n",
    "                mean_color = mean_neighbour_pixel(image, x, y)\n",
    "                image[y, x] = mean_color\n",
    "      \n",
    "    \n",
    "def mean_neighbour_pixel(image, x , y):\n",
    "    #Luam valoriile pixelilor vecini\n",
    "    #neighbour_pixels = []\n",
    "    neighbour_pixels = [\n",
    "        image[y-1, x-1], #stanga-sus\n",
    "        image[y-1, x],   #deasupra\n",
    "        image[y-1, x+1], #dreapta-sus\n",
    "    ]\n",
    "            \n",
    "    #Calculam culoarea media\n",
    "    mean_color = np.mean(neighbour_pixels, axis=0).astype(int)\n",
    "    \n",
    "    return mean_color \n",
    "\n",
    "def images_To_Numpy(dataloader, max_iter):\n",
    "    poze_test_data = []\n",
    "    poze_preprocesate = []\n",
    "    poze_masca_BGR = []\n",
    "    for images, labels in dataloader:\n",
    "        x_data = images.numpy() # tensor -> numpy\n",
    "        poze_test_data.append(x_data)   #inseram toate pozele din dataloader intr-o lista\n",
    "    poze_test_data = np.array(poze_test_data) #convertim lista in np.array\n",
    "    #print(poze_test_data.shape)  #(992, 1, 3, 224, 224)    nr elem - batch_size - channels - height - width   \n",
    "\n",
    "    \n",
    "    contor = 0\n",
    "    for i in range(poze_test_data.shape[0]):\n",
    "        if contor < max_iter:\n",
    "            img = poze_test_data[i,0]  #poza cu poza fara batch_size (3, 224, 224)\n",
    "            img_v2 = poze_test_data[i] #poza cu poza CU batch pt partea a 2-a\n",
    "            poze_preprocesate.append(img_v2)\n",
    "            \n",
    "            # Transpose the dimensions of img so that color channels are last\n",
    "            img_T = np.transpose(img, (1,2,0))              # shape : (224, 224, 3)\n",
    "        \n",
    "            # Convert the image to the BGR color space\n",
    "            img_BGR = cv2.cvtColor(img_T, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "                \n",
    "            poze_masca_BGR.append(img_BGR) # bagam intr-o lista\n",
    "        \n",
    "        \n",
    "            contor += 1\n",
    "        \n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    poze_masca_BGR = np.array(poze_masca_BGR) # facem numpy\n",
    "    poze_preprocesate = np.array(poze_preprocesate)\n",
    "    \n",
    "    return poze_preprocesate\n",
    "\n",
    "def afisare_openCV(images):\n",
    "    cv2.imshow(\"Imagini\", images)\n",
    "    cv2.waitKey(1000)\n",
    "    \n",
    "w1 = 224\n",
    "h1 = 224\n",
    "#def segmentare_1 (dataloader, photo_number):\n",
    "#    poze_preprocesate = images_To_Numpy(dataloader, photo_number)\n",
    "\n",
    "def segmentare_1 (dataloader, poze_preprocesate):\n",
    "    \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    \n",
    "    print(poze_preprocesate.shape)\n",
    "    for i in range(poze_preprocesate.shape[0]):\n",
    "        image = poze_preprocesate[i,0]\n",
    "        image_T = np.transpose(image, (1,2,0))\n",
    "        image_RGB = cv2.cvtColor(image_T, cv2.COLOR_BGR2RGB)\n",
    "        image_RGB = (image_RGB - np.min(image_RGB)) / (np.max(image_RGB) - np.min(image_RGB))\n",
    "        image_RGB = (image_RGB * 255).astype(np.uint8)\n",
    "        \n",
    "        #Detectam fete in imaginile color\n",
    "        rects = detector(image_RGB, 1)\n",
    "       # afisare_openCV(image_RGB)\n",
    "        \n",
    "        #Trecem prin fiecare detectare de fata\n",
    "        for (j, rect) in enumerate(rects):\n",
    "            #aplicam facial landmark detection => 68 (x,y) coordonate care mapeaza diverse trasaturi ale fetei\n",
    "            shape = predictor(image_RGB, rect)\n",
    "            shape = face_utils.shape_to_np(shape)   #shape_to_np(shape): Converts the facial landmark shape object (from dlib) to a NumPy array.\n",
    "        \n",
    "        \n",
    "            #convertim dreptunghiul dlib => OpenCV bounding box [(x,y,w,h)]\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect) #rect_to_bb(rect): Converts a rectangle object (from dlib) to a tuple of bounding box coordinates (x, y, w, h).\n",
    "        \n",
    "        ##Vreau sa incerc sa fac o functie de taiere de gradul 2.\n",
    "    \n",
    "        #Pasul1. definim coodronatele de interes\n",
    "        landmark_x1 = [shape[1,0], shape[27,0], shape[15,0]]\n",
    "        landmark_y1 = [shape[1,1], shape[27,1], shape[15,1]]\n",
    "    \n",
    "        #Pasul2. UtilizÄƒm curve_fit ca sÄƒ potrivim funcÈ›ia cu punctele de interes\n",
    "        popt_1, _ = curve_fit(quadratic_function, landmark_x1, landmark_y1)\n",
    "        \n",
    "        #Pasul3. GenerÄƒm masca sinteticÄƒ care va elimina masca din pozÄƒ\n",
    "        mask_shape = np.zeros_like(image_RGB, dtype = np.uint8)\n",
    "        h1, w1 = image_RGB.shape[:2]\n",
    "\n",
    "        \n",
    "        for x1 in range(w1):\n",
    "            for y1 in range(h1):\n",
    "                if (\n",
    "                    (y1 >= quadratic_function(x1, *popt_1)) and\n",
    "                    (y1 <= shape[8,1]) and\n",
    "                    (x1 >= shape[2,0] and x1 < shape[16,0])\n",
    "\n",
    "                ):                                          # *popt sa luam element cu element din vector <=>\n",
    "                    mask_shape[y1, x1, :] = 0               # <=> quadratic_function(x1,popt[0], popt[1], popt[2]) (Ã®n cazul acesta)\n",
    "                else:\n",
    "                    mask_shape[y1,x1,:] = 1\n",
    "\n",
    "\n",
    "\n",
    "        # AplicÄƒm masca sinteticÄƒ pe poza noastrab\n",
    "        masked_image = image_RGB * mask_shape\n",
    "        \n",
    "        # Show the masked image\n",
    "       # cv2.imshow(\"Masked Image\", masked_image)\n",
    "        #cv2.waitKey(2000)\n",
    "        \n",
    "    return masked_image\n",
    "        \n",
    "#def segmentare_2 (dataloader, photo_number):\n",
    "    #poze_preprocesate_1 = images_To_Numpy(dataloader, photo_number)\n",
    "\n",
    "def segmentare_2 (dataloader, poze_preprocesate_1):\n",
    "    \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    \n",
    "    for i in range(poze_preprocesate_1.shape[0]):\n",
    "        image = poze_preprocesate_1[i,0]\n",
    "        image_T = np.transpose(image, (1,2,0))\n",
    "        image_RGB = cv2.cvtColor(image_T, cv2.COLOR_BGR2RGB)\n",
    "        image_RGB = (image_RGB - np.min(image_RGB)) / (np.max(image_RGB) - np.min(image_RGB))\n",
    "        image_RGB = (image_RGB * 255).astype(np.uint8)\n",
    "        \n",
    "        #Detectam fete in imaginile color\n",
    "        rects = detector(image_RGB, 1)\n",
    "        #afisare_openCV(image_RGB)\n",
    "        \n",
    "        #Trecem prin fiecare detectare de fata\n",
    "        for (j, rect) in enumerate(rects):\n",
    "            #aplicam facial landmark detection => 68 (x,y) coordonate care mapeaza diverse trasaturi ale fetei\n",
    "            shape = predictor(image_RGB, rect)\n",
    "            shape = face_utils.shape_to_np(shape)   #shape_to_np(shape): Converts the facial landmark shape object (from dlib) to a NumPy array.\n",
    "        \n",
    "        \n",
    "            #convertim dreptunghiul dlib => OpenCV bounding box [(x,y,w,h)]\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect) #rect_to_bb(rect): Converts a rectangle object (from dlib) to a tuple of bounding box coordinates (x, y, w, h).\n",
    "        \n",
    "        ##Vreau sa incerc sa fac o functie de taiere de gradul 2.\n",
    "    \n",
    "        #Pasul1. definim coodronatele de interes\n",
    "        landmark_x1 = [shape[1,0], shape[27,0], shape[15,0]]\n",
    "        landmark_y1 = [shape[1,1], shape[27,1], shape[15,1]]\n",
    "    \n",
    "        #Pasul2. UtilizÄƒm curve_fit ca sÄƒ potrivim funcÈ›ia cu punctele de interes\n",
    "        popt_1, _ = curve_fit(quadratic_function, landmark_x1, landmark_y1)\n",
    "        \n",
    "        #Pasul3. GenerÄƒm masca sinteticÄƒ care va elimina masca din pozÄƒ\n",
    "        mask_shape_1 = np.zeros_like(image_RGB, dtype = np.uint8)\n",
    "        h1, w1 = image_RGB.shape[:2]\n",
    "\n",
    "        \n",
    "        for x1 in range(w1):\n",
    "            for y1 in range(h1):\n",
    "                if (\n",
    "                    (y1 >= quadratic_function(x1, *popt_1)) and\n",
    "                    (y1 <= shape[8,1]) and\n",
    "                    (x1 >= shape[2,0] and x1 < shape[16,0])\n",
    "\n",
    "                ):                                          # *popt sa luam element cu element din vector <=>\n",
    "                    mask_shape_1[y1, x1, :] = 1               # <=> quadratic_function(x1,popt[0], popt[1], popt[2]) (Ã®n cazul acesta)\n",
    "                else:\n",
    "                    mask_shape_1[y1,x1,:] = 0\n",
    "\n",
    "\n",
    "\n",
    "        # AplicÄƒm masca sinteticÄƒ pe poza noastrab\n",
    "        masked_image_1 = image_RGB * mask_shape_1\n",
    "        \n",
    "         # Show the masked image\n",
    "        #cv2.imshow(\"Masked Image\", masked_image_1)\n",
    "        #cv2.waitKey(2000)\n",
    "        \n",
    "    return masked_image_1   \n",
    "\n",
    "def afisare_finala_openCV(images):\n",
    "    cv2.imshow(\"Imagini\", images)\n",
    "    cv2.waitKey(10000)\n",
    "    \n",
    "def quadratic_function(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "\n",
    "#1. seturi de date \n",
    "transform_test, image_Datasets_WithMask,image_Datasets_WithoutMask,dataloaders_WithMask,dataloaders_WithoutMask = import_and_do_datasets(URL1, URL2)\n",
    "\n",
    "#2 model_masca\n",
    "prediction_mask = model_mask_output(\"E:\\\\Profil\\\\Desktop\\\\Licenta\\\\ISIA\\\\LICENTA\\\\persoane\\\\Dataset\\\\Test\\\\Buli\\\\1.png\", 'buli_nr_1.pth')\n",
    "print(prediction_mask)\n",
    "\n",
    "if prediction_mask == 0:\n",
    "    print(\"Persoana nu poartÄƒ mascÄƒ\")\n",
    "else:\n",
    "    #3 model_persoana\n",
    "    prediction_people = model_people(\"E:\\\\Profil\\\\Desktop\\\\Licenta\\\\ISIA\\\\LICENTA\\\\persoane\\\\Dataset\\\\Test\\\\Buli\\\\1.png\", 'model_persoane.pth')\n",
    "    person = check_person(prediction_people)\n",
    "    print(person)\n",
    "    \n",
    "    #4 segmentam persoana\n",
    "    poze_preprocesate = images_To_Numpy(dataloaders_WithMask, person)\n",
    "    poze_preprocesate_1 = images_To_Numpy(dataloaders_WithoutMask, person)\n",
    "\n",
    "    cu_masca = segmentare_1(dataloaders_WithMask, poze_preprocesate)\n",
    "    fara_masca = segmentare_2(dataloaders_WithoutMask, poze_preprocesate_1)\n",
    "    \n",
    "    #5\n",
    "    reconstructie = cu_masca + fara_masca\n",
    "    replace_red_with_color(reconstructie)\n",
    "    replace_cyan_with_color(reconstructie)\n",
    "    replace_green_with_color(reconstructie)\n",
    "    replace_black_with_color(reconstructie)\n",
    "    afisare_finala_openCV(reconstructie)\n",
    "    \n",
    "    cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
